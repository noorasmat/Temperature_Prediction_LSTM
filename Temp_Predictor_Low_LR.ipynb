{"cells":[{"cell_type":"markdown","source":["###Temperature Prediction Using IoT Sensor Data\n","The data used in this notebook model consists of temperature readings collected from IoT temperature sensors. The primary purpose of this model is to predict future temperature values based on historical data. This is achieved by training a Long Short-Term Memory (LSTM) neural network, which is particularly well-suited for time series forecasting due to its ability to capture temporal dependencies."],"metadata":{"id":"H92jeoB3SyXW"},"id":"H92jeoB3SyXW"},{"cell_type":"code","source":["#Adding neccessary python packages\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from keras.callbacks import ModelCheckpoint\n","import keras\n","from tensorflow.keras.layers import LSTM, Dense, Reshape, Dense\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.callbacks import ModelCheckpoint"],"metadata":{"id":"BdtUkVyihxzR","executionInfo":{"status":"ok","timestamp":1725702316478,"user_tz":420,"elapsed":6353,"user":{"displayName":"Noori Syed","userId":"15299885683034347730"}}},"id":"BdtUkVyihxzR","execution_count":2,"outputs":[]},{"cell_type":"code","source":["mode='colab'\n","#mode='local'\n","learning_rate=0.001\n","opt = keras.optimizers.Adam(learning_rate)\n","Epochs=20"],"metadata":{"id":"f6ZElPSstjJ5","executionInfo":{"status":"ok","timestamp":1725702316478,"user_tz":420,"elapsed":8,"user":{"displayName":"Noori Syed","userId":"15299885683034347730"}}},"id":"f6ZElPSstjJ5","execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["###Data Loading"],"metadata":{"id":"W6dVg-9FUEJc"},"id":"W6dVg-9FUEJc"},{"cell_type":"code","source":["#Set local system or colab if using google colaboratory\n","from google.colab import drive\n","if mode=='colab':\n","  drive.mount('/content/drive')\n","  # Load dataset\n","  data = pd.read_csv('/content/drive/My Drive/Colab_Notebooks/0_Temperature_Prediction/IOT-temp.csv')\n","else:\n","  data = pd.read_csv('IOT-temp.csv')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DywbcYl_h0DE","executionInfo":{"status":"ok","timestamp":1725702367447,"user_tz":420,"elapsed":50975,"user":{"displayName":"Noori Syed","userId":"15299885683034347730"}},"outputId":"843f01f8-d1f5-48ff-c881-bfc96d2a14a9"},"id":"DywbcYl_h0DE","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["###Data Details and visulaiztion"],"metadata":{"id":"Nq5H0SZaUCIF"},"id":"Nq5H0SZaUCIF"},{"cell_type":"code","execution_count":5,"id":"b365fff4-d9a7-44b7-b1e7-18cbc8e90192","metadata":{"id":"b365fff4-d9a7-44b7-b1e7-18cbc8e90192","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725702367448,"user_tz":420,"elapsed":13,"user":{"displayName":"Noori Syed","userId":"15299885683034347730"}},"outputId":"c2540ae8-bd7c-4491-cf5b-0bdc8efdb0e2"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 97606 entries, 0 to 97605\n","Data columns (total 5 columns):\n"," #   Column      Non-Null Count  Dtype \n","---  ------      --------------  ----- \n"," 0   id          97606 non-null  object\n"," 1   room_id/id  97606 non-null  object\n"," 2   noted_date  97606 non-null  object\n"," 3   temp        97606 non-null  int64 \n"," 4   out/in      97606 non-null  object\n","dtypes: int64(1), object(4)\n","memory usage: 3.7+ MB\n","None\n","               temp\n","count  97606.000000\n","mean      35.053931\n","std        5.699825\n","min       21.000000\n","25%       30.000000\n","50%       35.000000\n","75%       40.000000\n","max       51.000000\n"]}],"source":["# Display basic information and check for missing values\n","print(data.info())\n","print(data.describe())\n","\n","# Plot temperature over time\n","#plt.plot(data['temp'], data['noted_date'])\n","#plt.xlabel('Time')\n","#plt.ylabel('Temperature')\n","#plt.title('Temperature Over Time')\n","#plt.show()"]},{"cell_type":"code","source":["print(data.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NYfRxyG6M4qx","executionInfo":{"status":"ok","timestamp":1725702367448,"user_tz":420,"elapsed":12,"user":{"displayName":"Noori Syed","userId":"15299885683034347730"}},"outputId":"b646dd42-25d3-40f8-a763-f3249e1e78ee"},"id":"NYfRxyG6M4qx","execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["                                    id  room_id/id        noted_date  temp  \\\n","0  __export__.temp_log_196134_bd201015  Room Admin  08-12-2018 09:30    29   \n","1  __export__.temp_log_196131_7bca51bc  Room Admin  08-12-2018 09:30    29   \n","2  __export__.temp_log_196127_522915e3  Room Admin  08-12-2018 09:29    41   \n","3  __export__.temp_log_196128_be0919cf  Room Admin  08-12-2018 09:29    41   \n","4  __export__.temp_log_196126_d30b72fb  Room Admin  08-12-2018 09:29    31   \n","\n","  out/in  \n","0     In  \n","1     In  \n","2    Out  \n","3    Out  \n","4     In  \n"]}]},{"cell_type":"markdown","source":["#Pre-Processing/Data Preperation"],"metadata":{"id":"ATZ94ijmURSf"},"id":"ATZ94ijmURSf"},{"cell_type":"markdown","source":["###Remving Duplicates"],"metadata":{"id":"8YlO3pZZUZeg"},"id":"8YlO3pZZUZeg"},{"cell_type":"markdown","source":["The sensor data, shows two entries for each time, i.e., date_noted. And for both entries the time and the temperature are same. So we need to remove them and take only unique time and temperature."],"metadata":{"id":"HlhI1_3RVkcY"},"id":"HlhI1_3RVkcY"},{"cell_type":"code","source":["# Create a new DataFrame with unique timestamps and their corresponding temperatures\n","unique_data = data.drop_duplicates(subset=['noted_date'], keep='first')\n","\n","# Print the shape of the original and new DataFrames to see the difference\n","print(f\"Original data shape: {data.shape}\")\n","print(f\"Unique data shape: {unique_data.shape}\")\n","print(unique_data.head())\n","unique_data.to_csv('unique_temperatures.csv', index=False)  # Save to CSV if needed"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"94alNLJyPMSP","executionInfo":{"status":"ok","timestamp":1725702367448,"user_tz":420,"elapsed":10,"user":{"displayName":"Noori Syed","userId":"15299885683034347730"}},"outputId":"876a3c4b-32a2-4352-b115-db759830228f"},"id":"94alNLJyPMSP","execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Original data shape: (97606, 5)\n","Unique data shape: (27920, 5)\n","                                     id  room_id/id        noted_date  temp  \\\n","0   __export__.temp_log_196134_bd201015  Room Admin  08-12-2018 09:30    29   \n","2   __export__.temp_log_196127_522915e3  Room Admin  08-12-2018 09:29    41   \n","6   __export__.temp_log_196121_01544d45  Room Admin  08-12-2018 09:28    29   \n","8   __export__.temp_log_196111_6b7a0848  Room Admin  08-12-2018 09:26    29   \n","10  __export__.temp_log_196108_4a983c7e  Room Admin  08-12-2018 09:25    42   \n","\n","   out/in  \n","0      In  \n","2     Out  \n","6      In  \n","8      In  \n","10    Out  \n"]}]},{"cell_type":"markdown","source":["The data is to be reversed, becuase the time is to be in increasing order. Future prediction will be based on the last minutes temperature. Say T3, T2, T1. So better to reverse the order, It makes good sense."],"metadata":{"id":"MVNQ8bJrU-hp"},"id":"MVNQ8bJrU-hp"},{"cell_type":"code","source":["#Check the reversing order\n","print('Actual Sequence:',unique_data['temp'], 'Reversed Sequence:',np.flip(unique_data['temp']))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bJTeaoJSuxB_","executionInfo":{"status":"ok","timestamp":1725702367448,"user_tz":420,"elapsed":8,"user":{"displayName":"Noori Syed","userId":"15299885683034347730"}},"outputId":"adc7ef03-cbfd-4248-bb34-0980398f4b1d"},"id":"bJTeaoJSuxB_","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Actual Sequence: 0        29\n","2        41\n","6        29\n","8        29\n","10       42\n","         ..\n","97568    31\n","97569    32\n","97571    31\n","97576    31\n","97603    31\n","Name: temp, Length: 27920, dtype: int64 Reversed Sequence: 97603    31\n","97576    31\n","97571    31\n","97569    32\n","97568    31\n","         ..\n","10       42\n","8        29\n","6        29\n","2        41\n","0        29\n","Name: temp, Length: 27920, dtype: int64\n"]}]},{"cell_type":"code","source":["Temp=np.flip(unique_data['temp'])\n","print(Temp.shape)"],"metadata":{"id":"GB0LIFyRue7p","executionInfo":{"status":"ok","timestamp":1725702367448,"user_tz":420,"elapsed":6,"user":{"displayName":"Noori Syed","userId":"15299885683034347730"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"71c9e2a8-a23e-4454-9f8a-cd77d6f47934"},"id":"GB0LIFyRue7p","execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["(27920,)\n"]}]},{"cell_type":"markdown","source":["###Handling Missing Values"],"metadata":{"id":"CLgAthDKV62o"},"id":"CLgAthDKV62o"},{"cell_type":"code","source":["# Handling missing values (if any)\n","Temp.interpolate(method='linear', inplace=True)"],"metadata":{"id":"Lc4ArxqkjkD3","executionInfo":{"status":"ok","timestamp":1725702367449,"user_tz":420,"elapsed":5,"user":{"displayName":"Noori Syed","userId":"15299885683034347730"}}},"id":"Lc4ArxqkjkD3","execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["###Data Normalization, to make it of same range. For better learning."],"metadata":{"id":"GFXxE8dZWFB9"},"id":"GFXxE8dZWFB9"},{"cell_type":"code","source":["from sklearn.preprocessing import MinMaxScaler\n","\n","# Scaling temperature data to [0, 1]\n","scaler = MinMaxScaler(feature_range=(0, 1))\n","scaled_temperature = scaler.fit_transform(Temp.values.reshape(-1, 1))"],"metadata":{"id":"H_djooWblBiC","executionInfo":{"status":"ok","timestamp":1725702368009,"user_tz":420,"elapsed":564,"user":{"displayName":"Noori Syed","userId":"15299885683034347730"}}},"id":"H_djooWblBiC","execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["Use this if needed, For similicity, Lets suppose we do not split, and just focus on training accuracy."],"metadata":{"id":"pqidxQFOs5w8"},"id":"pqidxQFOs5w8"},{"cell_type":"code","source":["# Split the data into training and testing sets\n","#train_size = int(len(scaled_temperature) * 0.8)\n","#test_size = len(scaled_temperature) - train_size\n","#train_data = scaled_temperature[0:train_size]\n","#test_data = scaled_temperature[train_size:len(scaled_temperature)]"],"metadata":{"id":"Fgz2WOGKssdT","executionInfo":{"status":"ok","timestamp":1725702368009,"user_tz":420,"elapsed":9,"user":{"displayName":"Noori Syed","userId":"15299885683034347730"}}},"id":"Fgz2WOGKssdT","execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["In time series forecasting, especially when using models like LSTMs, GRUs, or other sequence-based models, **`n_steps_in`** and **`n_steps_out`** refer to the number of time steps used for input (past data) and output (future predictions), respectively.\n","\n","### Definitions with 10 steps:\n","\n","1. **`n_steps_in = 10` (Input Sequence Length)**:\n","   - This means the model will look at the last 10 time steps (or data points) from the past to make predictions about the future.\n","   - Example: If `n_steps_in = 10`, the model uses data from the last 10 minutes (or 10 time steps, depending on your data frequency).\n","\n","2. **`n_steps_out = 10` (Output Sequence Length)**:\n","   - This means the model will predict the next 10 time steps based on the input sequence.\n","   - Example: If `n_steps_out = 10`, the model predicts the temperature for the next 10 minutes (or time steps).\n","\n","### Example for `n_steps_in = 10` and `n_steps_out = 10`:\n","\n","Assume you have temperature data for every minute, and you want to predict the next 10 minutes based on the last 10 minutes of data. Here:\n","- **`n_steps_in = 10`**: The model looks at data from the last 10 minutes.\n","- **`n_steps_out = 10`**: The model predicts the temperature for the next 10 minutes.\n","\n","### Sliding Window Approach with 10 Steps:\n","The data is structured into input-output pairs:\n","- Input (`n_steps_in = 10`) → Output (`n_steps_out = 10`).\n","\n","For example, if you have temperature data like `[t1, t2, t3, ..., tn]`:\n","- For the first window: `[t1, t2, ..., t10]` → `[t11, t12, ..., t20]`.\n","- For the next window, the sequence moves forward by one step: `[t2, t3, ..., t11]` → `[t12, t13, ..., t21]`.\n","\n","This helps train the model to predict the temperature for the next 10 time steps based on the previous 10 time steps of data."],"metadata":{"id":"ggq5Y9SHWQ4v"},"id":"ggq5Y9SHWQ4v"},{"cell_type":"code","source":["n_steps_in = 10  # Last 10 minutes as input\n","n_steps_out = 10  # Predict next 10 minutes\n","\n","# Prepare input/output sequences\n","X, y = [], []\n","for i in range(len(scaled_temperature) - n_steps_in - n_steps_out + 1):\n","    X.append(scaled_temperature[i:i + n_steps_in])\n","    y.append(scaled_temperature[i + n_steps_in:i + n_steps_in + n_steps_out])\n","\n","X, y = np.array(X), np.array(y)\n","\n","# Reshape input to be 3D [samples, timesteps, features] for LSTM\n","X = X.reshape((X.shape[0], X.shape[1], 1))"],"metadata":{"id":"019wgx-dlXpy","executionInfo":{"status":"ok","timestamp":1725702368010,"user_tz":420,"elapsed":9,"user":{"displayName":"Noori Syed","userId":"15299885683034347730"}}},"id":"019wgx-dlXpy","execution_count":13,"outputs":[]},{"cell_type":"code","source":["print(X.shape)\n","print(y.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KdYsFZZmaqeN","executionInfo":{"status":"ok","timestamp":1725702368010,"user_tz":420,"elapsed":9,"user":{"displayName":"Noori Syed","userId":"15299885683034347730"}},"outputId":"025f2850-aa18-4e90-ea21-55d828044065"},"id":"KdYsFZZmaqeN","execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["(27901, 10, 1)\n","(27901, 10, 1)\n"]}]},{"cell_type":"code","source":["# Define the LSTM model\n","lstm_model = Sequential()\n","\n","# LSTM layer with return_sequences=True to output a sequence for each time step\n","lstm_model.add(LSTM(50, activation='relu', return_sequences=False, input_shape=(n_steps_in, 1)))\n","\n","# Fully connected (Dense) layer that outputs the next 10 minutes\n","lstm_model.add(Dense(n_steps_out * 1))  # Produces 10 outputs (1 for each future minute)\n","\n","# Reshape the output to be (10, 1) for 10 time steps with 1 feature (temperature)\n","lstm_model.add(Reshape((n_steps_out, 1)))\n","\n","# Compile the model\n","lstm_model.compile(optimizer=opt, loss='mse')\n","\n","# Define the ModelCheckpoint callback to save the best model based on validation loss\n","checkpoint = ModelCheckpoint('Temperature_predictor.keras', monitor='val_loss', save_best_only=True, mode='min')\n","\n","# Train the model\n","lstm_model.fit(X, y, epochs=Epochs, batch_size=32, callbacks=[checkpoint])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h8gCzdeFmeiN","executionInfo":{"status":"ok","timestamp":1725702516657,"user_tz":420,"elapsed":148654,"user":{"displayName":"Noori Syed","userId":"15299885683034347730"}},"outputId":"94d0538a-8519-4197-f88d-1ffa0937c824"},"id":"h8gCzdeFmeiN","execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0593\n","Epoch 2/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/callbacks/model_checkpoint.py:206: UserWarning: Can save best model only with val_loss available, skipping.\n","  self._save_model(epoch=epoch, batch=None, logs=logs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.0194\n","Epoch 3/20\n","\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - loss: 0.0192\n","Epoch 4/20\n","\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0189\n","Epoch 5/20\n","\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0191\n","Epoch 6/20\n","\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0192\n","Epoch 7/20\n","\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0190\n","Epoch 8/20\n","\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0190\n","Epoch 9/20\n","\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0189\n","Epoch 10/20\n","\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0190\n","Epoch 11/20\n","\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0190\n","Epoch 12/20\n","\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0190\n","Epoch 13/20\n","\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - loss: 0.0188\n","Epoch 14/20\n","\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0186\n","Epoch 15/20\n","\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - loss: 0.0186\n","Epoch 16/20\n","\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0186\n","Epoch 17/20\n","\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0186\n","Epoch 18/20\n","\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0186\n","Epoch 19/20\n","\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - loss: 0.0188\n","Epoch 20/20\n","\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0183\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7e52586a60e0>"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["###Saving Model Weights"],"metadata":{"id":"QeYQxteDXIV3"},"id":"QeYQxteDXIV3"},{"cell_type":"code","source":["lstm_model.save('Temperature_predictor.keras')\n","#lstm_model.load('Temperature_predictor.keras')"],"metadata":{"id":"NLimgaxUzAqy","executionInfo":{"status":"ok","timestamp":1725702516657,"user_tz":420,"elapsed":8,"user":{"displayName":"Noori Syed","userId":"15299885683034347730"}}},"id":"NLimgaxUzAqy","execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["###EValuate Model on X"],"metadata":{"id":"kWwLnqjUXPYz"},"id":"kWwLnqjUXPYz"},{"cell_type":"code","source":["# Evaluate the baseline model\n","predictions = lstm_model.predict(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LS-iiIkVlh-Z","executionInfo":{"status":"ok","timestamp":1725702519121,"user_tz":420,"elapsed":2470,"user":{"displayName":"Noori Syed","userId":"15299885683034347730"}},"outputId":"b38b185d-d1a0-4737-cbc8-d7912f398981"},"id":"LS-iiIkVlh-Z","execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n"]}]},{"cell_type":"code","source":["print(predictions.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jx7J1E_ii5EX","executionInfo":{"status":"ok","timestamp":1725702519121,"user_tz":420,"elapsed":10,"user":{"displayName":"Noori Syed","userId":"15299885683034347730"}},"outputId":"34ea03a7-ba88-4927-f70b-f8e4d04082eb"},"id":"Jx7J1E_ii5EX","execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["(27901, 10, 1)\n"]}]},{"cell_type":"code","source":["#Flattening for MSE\n","y_flattened = y.flatten()\n","predictions_flattened = predictions.flatten()\n","\n","print(f\"Shape of flattened y: {y_flattened.shape}\")\n","print(f\"Shape of flattened predictions: {predictions_flattened.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iIhFsE5StSpS","executionInfo":{"status":"ok","timestamp":1725702519122,"user_tz":420,"elapsed":8,"user":{"displayName":"Noori Syed","userId":"15299885683034347730"}},"outputId":"61b21f96-ee3e-449b-9688-cd02dd6a1a07"},"id":"iIhFsE5StSpS","execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of flattened y: (279010,)\n","Shape of flattened predictions: (279010,)\n"]}]},{"cell_type":"code","source":["#Find the mean squared error between y and predictions\n","\n","from sklearn.metrics import mean_squared_error\n","\n","mse = mean_squared_error(y_flattened, predictions_flattened)\n","print(f\"Mean Squared Error: {mse}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mmtv5EjXxMhc","executionInfo":{"status":"ok","timestamp":1725702519610,"user_tz":420,"elapsed":494,"user":{"displayName":"Noori Syed","userId":"15299885683034347730"}},"outputId":"c70751a8-46a8-4b5f-9e3a-211d28c53862"},"id":"Mmtv5EjXxMhc","execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean Squared Error: 0.018842858552445475\n"]}]},{"cell_type":"markdown","source":["###Pick the last temperature window, and predict future next, Reverse transform"],"metadata":{"id":"K0hZlzMQYGcV"},"id":"K0hZlzMQYGcV"},{"cell_type":"code","source":["#print last prediction index\n","predicted_temperature = scaler.inverse_transform(predictions[-1])\n","print('Next 10 days temperature using previous 10 days: ',predicted_temperature)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ruFIIa6UrvX3","executionInfo":{"status":"ok","timestamp":1725702519610,"user_tz":420,"elapsed":5,"user":{"displayName":"Noori Syed","userId":"15299885683034347730"}},"outputId":"20228778-f4f7-4c4b-9a53-c14e9735be2f"},"id":"ruFIIa6UrvX3","execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Next 10 days temperature using previous 10 days:  [[34.78167 ]\n"," [34.852863]\n"," [35.25414 ]\n"," [35.282703]\n"," [35.172195]\n"," [35.43152 ]\n"," [35.527412]\n"," [35.561497]\n"," [35.67424 ]\n"," [35.83145 ]]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Q5BDerAgsLpJ","executionInfo":{"status":"ok","timestamp":1725702519610,"user_tz":420,"elapsed":3,"user":{"displayName":"Noori Syed","userId":"15299885683034347730"}}},"id":"Q5BDerAgsLpJ","execution_count":21,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}